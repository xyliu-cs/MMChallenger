{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7hmEGCmk0RM"
      },
      "source": [
        "# Synonym Filtereing Model\n",
        "**Phrase-BERT**: Improved Phrase Embeddings from BERT with an Application to Corpus Exploration (EMNLP, 2020)\n",
        "\n",
        "[[Paper]](https://arxiv.org/pdf/2109.06304.pdf) [[Hugging Face]](https://huggingface.co/whaleloops/phrase-bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX5Jda49RFCv"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('whaleloops/phrase-bert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3PZTwh4Oneo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "# place ground-truth sentence at phrase_list[0], distractor at phrase_list[1]\n",
        "def check_cos_sim(model, phrase_list, threshold):\n",
        "    phrase_embs = model.encode(phrase_list)\n",
        "    [gt, dt, op1, op2, op3] = phrase_embs\n",
        "    cos_sim = nn.CosineSimilarity(dim=0)\n",
        "    all_distant = True\n",
        "    closeness = []\n",
        "    cos_sim_list = []\n",
        "    cos_sim_list.append(cos_sim(torch.tensor(gt), torch.tensor(dt)))\n",
        "    cos_sim_list.append(cos_sim(torch.tensor(gt), torch.tensor(op1)))\n",
        "    cos_sim_list.append(cos_sim(torch.tensor(gt), torch.tensor(op2)))\n",
        "    cos_sim_list.append(cos_sim(torch.tensor(gt), torch.tensor(op3)))\n",
        "\n",
        "    cos_sim_list.append(cos_sim(torch.tensor(dt), torch.tensor(op1)))\n",
        "    cos_sim_list.append(cos_sim(torch.tensor(dt), torch.tensor(op2)))\n",
        "    cos_sim_list.append(cos_sim(torch.tensor(dt), torch.tensor(op3)))\n",
        "\n",
        "    for i in range(len(cos_sim_list)):\n",
        "        if cos_sim_list[i] > threshold:\n",
        "            closeness.append((i//4, (i//4)+(i%4)+1))\n",
        "            all_distant = False\n",
        "            print(f\"[Warning] [{phrase_list[i//4]}] - [{phrase_list[(i//4)+(i%4)+1]}]: {cos_sim_list[i]}; Current threshold is {threshold}\")\n",
        "    return closeness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jScnoNSrWAV"
      },
      "source": [
        "# Read Raw Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PLIRhZoKt5Z"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"/home/liu/temp_question/sentence_lookup_vicuna_2024-03-01.json\", 'r') as f:\n",
        "    vicuna_data = json.load(f)\n",
        "sent_data_vicuna = vicuna_data[\"data\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZueUkTwrKwAm",
        "outputId": "82e12d2b-4b4d-4d20-e74a-4afc63d9359c"
      },
      "outputs": [],
      "source": [
        "subjs = []\n",
        "for sent_dict in sent_data_vicuna:\n",
        "    if sent_dict['subj'] not in subjs:\n",
        "        subjs.append(sent_dict['subj'])\n",
        "print(subjs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv8YsTQFjndL"
      },
      "source": [
        "# Base Sentence/Language Prior Selection \n",
        "_Extended Reservoir Sampling_ with _k_ = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import deque\n",
        "\n",
        "subjects_queue = deque(subjs)\n",
        "global_subject_count = {}\n",
        "\n",
        "for subj in subjs:\n",
        "    global_subject_count[subj] = 0\n",
        "\n",
        "base_sentences = {}\n",
        "reservoir_data = {}\n",
        "reservoir_counters = {}\n",
        "k = 5  # reservoir capacity\n",
        "while subjects_queue:\n",
        "    subject = subjects_queue.popleft()\n",
        "    rolling_idx = global_subject_count[subject]\n",
        "\n",
        "    compare_batch = []\n",
        "    for sent_dict in sent_data_vicuna:\n",
        "            if sent_dict['subj'] == subject:\n",
        "                compare_batch.append(sent_dict)        \n",
        "    assert(len(compare_batch) == 2500)\n",
        "    sorted_compare_list = sorted(compare_batch, key=lambda x: x['ppl'])\n",
        "    # local_candidates = sorted_compare_list[0:5]\n",
        "\n",
        "    for i in range(rolling_idx, len(sorted_compare_list)):\n",
        "        item = sorted_compare_list[i]\n",
        "        item_text = item['vp'] + ' ' + item['loc']  # e.g. [riding a bicycle in the countryside]\n",
        "        # print(item_text)\n",
        "        # If the 'text' value is not already a reservoir, initialize it\n",
        "        if item_text not in reservoir_data:\n",
        "            reservoir_data[item_text] = []\n",
        "            reservoir_counters[item_text] = 0\n",
        "        \n",
        "        # Increment the counter for the identified reservoir\n",
        "        reservoir_counters[item_text] += 1\n",
        "\n",
        "        # Check if the reservoir is not full\n",
        "        if len(reservoir_data[item_text]) < k:\n",
        "            reservoir_data[item_text].append(item) \n",
        "            break # move to next subject, but still can be replaced later\n",
        "        else:\n",
        "            # If the reservoir is full, decide whether to include the new item\n",
        "            if random.random() < k / reservoir_counters[item_text]:\n",
        "                # Select a random index to replace\n",
        "                replace_index = random.randint(0, k-1)\n",
        "                to_replace_subj = reservoir_data[item_text][replace_index]['subj']\n",
        "                global_subject_count[to_replace_subj] += 1\n",
        "                subjects_queue.append(to_replace_subj) # add to be re-find base sentence\n",
        "                reservoir_data[item_text][replace_index] = item # replace\n",
        "                break # move to next subject, but still can be replaced later\n",
        "            # else, continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_sentences = []\n",
        "for verb_loc_phrase, sent_list in reservoir_data.items():\n",
        "    print(f\"{[verb_loc_phrase]}, Count: {len(sent_list)}\")\n",
        "    for sent_dict in sent_list:\n",
        "        base_sentences.append(sent_dict)\n",
        "print(f\"Total: {len(subjs)}, Constructed: {len(base_sentences)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"base_sentences_0302.json\", 'w') as f:\n",
        "    json.dump(base_sentences, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpLABclsjvZY"
      },
      "source": [
        "# Question Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5JknxjXVcpN"
      },
      "outputs": [],
      "source": [
        "index_to_letter = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "with open('/home/liu/temp_question/base_sentences_0302.json', 'r') as f:\n",
        "    base_sentences = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verb Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moceLPp5jzfp"
      },
      "source": [
        "### Pure verb phrases (*for tuning threshold*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOG0EIzsLtHd",
        "outputId": "f560e201-85da-4d9f-96b7-38d8ed5cb40a"
      },
      "outputs": [],
      "source": [
        "# verb phrase test case construction\n",
        "verb_candidate_groups = {}\n",
        "ctr = 1\n",
        "for sent_dict in base_sentences:\n",
        "    subject = sent_dict[\"subj\"]\n",
        "    verb_phrase = sent_dict[\"vp\"]\n",
        "    location = sent_dict[\"loc\"]\n",
        "    candidate_batch = []\n",
        "    for sentence in sent_data:\n",
        "        if sentence['subj'] == subject and sentence['loc'] == location:\n",
        "            candidate_batch.append(sentence)\n",
        "    sorted_batch = sorted(candidate_batch, key=lambda x: x['ppl'])\n",
        "    assert(len(sorted_batch) == 50)\n",
        "\n",
        "    candidate_text_group = []\n",
        "\n",
        "    distractor = sent_dict.copy()\n",
        "    gt = sorted_batch[-4].copy()\n",
        "    candidate_text_group.append(gt['vp']) # need to append gt first\n",
        "    candidate_text_group.append(distractor['vp'])\n",
        "\n",
        "    for item in sorted_batch[-3:]:\n",
        "        candidate_text_group.append(item['vp'])\n",
        "\n",
        "    # if check_cos_sim(tokenizer, model, candidate_text_group, 0.8):\n",
        "    #     verb_candidate_groups[ctr] = local_tmp\n",
        "    #     ctr += 1\n",
        "\n",
        "    verb_candidate_groups[ctr] = candidate_text_group\n",
        "    ctr += 1\n",
        "\n",
        "print(f\"=====================\\nTotal valid questions: {ctr-1}\")\n",
        "with open('verb_options.json', 'w') as f:\n",
        "    json.dump(verb_candidate_groups, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEBd8U2Lj5Vi"
      },
      "source": [
        "### Verb candidates selection w/o ground-truth images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcLRd2wND2VH",
        "outputId": "915f46b8-f33b-4fa9-e3d5-3a78fd0bb2a3"
      },
      "outputs": [],
      "source": [
        "# verb phrase test case construction\n",
        "verb_candidate_groups = {}\n",
        "ctr = 1\n",
        "for sent_dict in left_over_bases:\n",
        "    subject = sent_dict[\"subj\"]\n",
        "    verb_phrase = sent_dict[\"vp\"]\n",
        "    location = sent_dict[\"loc\"]\n",
        "    candidate_batch = []\n",
        "    for sentence in sent_data_vicuna:\n",
        "        if sentence['subj'] == subject and sentence['loc'] == location:\n",
        "            candidate_batch.append(sentence)\n",
        "    sorted_batch = sorted(candidate_batch, key=lambda x: x['ppl'])\n",
        "    assert(len(sorted_batch) == 50)\n",
        "\n",
        "    gt_index = random.randint(40, 43)\n",
        "    gt = sorted_batch[gt_index].copy()\n",
        "    distractor = sent_dict.copy()\n",
        "    option1 = sorted_batch[45].copy()\n",
        "    option2 = sorted_batch[47].copy()\n",
        "    option3 = sorted_batch[49].copy()\n",
        "\n",
        "    chances = {'option1': 1, 'option2': 1, 'option3': 1}\n",
        "    gt_indices = [40, 41, 42, 43]\n",
        "    gt_indices.remove(gt_index)\n",
        "\n",
        "    need_further_iteration = True\n",
        "    candidate_sentences = [gt, distractor, option1, option2, option3]\n",
        "    while need_further_iteration:\n",
        "        candidate_verb_phrases = [item['vp'] for item in candidate_sentences]\n",
        "        print(f\"Group {ctr}: {candidate_verb_phrases}\")\n",
        "        conflicts = check_cos_sim(model, candidate_verb_phrases, 0.73) # tuned threshold\n",
        "        if len(conflicts) == 0:\n",
        "            print(f\"Group {ctr} Succeed.\\n========\")\n",
        "            candidate_sentences[0]['tag'] = 'ground-truth'\n",
        "            candidate_sentences[1]['tag'] = 'distractor'\n",
        "            candidate_sentences[2]['tag'] = 'option1'\n",
        "            candidate_sentences[3]['tag'] = 'option2'\n",
        "            candidate_sentences[4]['tag'] = 'option3'\n",
        "            for sent in candidate_sentences:\n",
        "                sent['gid'] = ctr\n",
        "            verb_candidate_groups[ctr] = candidate_sentences\n",
        "            ctr += 1\n",
        "            need_further_iteration = False\n",
        "        else:\n",
        "            resolved_all_conflicts = True\n",
        "            gt_needs_to_change = True if (0, 1) in conflicts else False\n",
        "            if gt_needs_to_change:\n",
        "                if len(gt_indices) == 0:\n",
        "                    print(f\"Group {ctr} Discarded due to unresolved gt-dt conflicts.\")\n",
        "                    resolved_all_conflicts = False\n",
        "                    need_further_iteration = False\n",
        "                    break\n",
        "                else:\n",
        "                    new_gt_index = random.choice(gt_indices)\n",
        "                    gt_indices.remove(new_gt_index)\n",
        "                    gt = sorted_batch[new_gt_index].copy()\n",
        "                    candidate_sentences[0] = gt\n",
        "                    conflicts = list(filter(lambda x: x[0] != 0, conflicts)) # options with gt are excluded\n",
        "\n",
        "            options_set = set()\n",
        "            for conflict in conflicts:\n",
        "                options_set.add(conflict[1])\n",
        "            print(options_set)\n",
        "            \n",
        "            for option in options_set:                    \n",
        "                if option == 2:  # Conflict with option1\n",
        "                    if chances['option1'] > 0:\n",
        "                        option1 = sorted_batch[44].copy()\n",
        "                        chances['option1'] -= 1\n",
        "                        candidate_sentences[2] = option1\n",
        "                    else:\n",
        "                        resolved_all_conflicts = False\n",
        "                        break\n",
        "                elif option == 3:  # Conflict with option2\n",
        "                    if chances['option2'] > 0:\n",
        "                        option2 = sorted_batch[46].copy()\n",
        "                        chances['option2'] -= 1\n",
        "                        candidate_sentences[3] = option2\n",
        "                    else:\n",
        "                        resolved_all_conflicts = False\n",
        "                        break\n",
        "                elif option == 4:  # Conflict with option3\n",
        "                    if chances['option3'] > 0:\n",
        "                        option3 = sorted_batch[48].copy()\n",
        "                        chances['option3'] -= 1\n",
        "                        candidate_sentences[4] = option3\n",
        "                    else:\n",
        "                        resolved_all_conflicts = False\n",
        "                        break\n",
        "            \n",
        "            if not resolved_all_conflicts:\n",
        "                print(f\"Group {ctr} Discarded due to unresolved option conflicts.\")\n",
        "                # print(candidate_sentences)\n",
        "                print(conflicts)\n",
        "                print(chances)\n",
        "\n",
        "                need_further_iteration = False\n",
        "    \n",
        "print(f\"=====================\\nTotal valid questions (Verb): {ctr-1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verb candidates selection w/ ground-truth images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('/home/liu/temp_question/ground_truth_sentences_2_24.json', 'r') as f:\n",
        "    ground_truth = json.load(f)\n",
        "ground_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# verb phrase test case construction\n",
        "# legacy selection logic of options = sorted_batch[-3:] is applied here\n",
        "verb_candidate_groups = {}\n",
        "ctr = 1\n",
        "for sent_dict in base_sentences:\n",
        "    subject = sent_dict[\"subj\"]\n",
        "    verb_phrase = sent_dict[\"vp\"]\n",
        "    location = sent_dict[\"loc\"]\n",
        "\n",
        "    candidate_batch = []\n",
        "    for sentence in sent_data_vicuna:\n",
        "        if sentence['subj'] == subject and sentence['loc'] == location:\n",
        "            candidate_batch.append(sentence)\n",
        "    sorted_batch = sorted(candidate_batch, key=lambda x: x['ppl'])\n",
        "    assert(len(sorted_batch) == 50)\n",
        "    candidate_verb_phrases = []\n",
        "    local_tmp = []\n",
        "\n",
        "    try:\n",
        "        gt = ground_truth[subject]  # {subject: [whole text, qid]}\n",
        "    except:\n",
        "        left_over_subjs.append(subject)\n",
        "        continue\n",
        "\n",
        "    distractor = sent_dict.copy()\n",
        "    distractor['tag'] = 'distractor'\n",
        "    distractor['gid'] = gt[1]\n",
        "\n",
        "    gt_dict = {}\n",
        "    gt_index = None\n",
        "    for i in range(len(sorted_batch)):\n",
        "        if sorted_batch[i]['text'] == gt[0]:\n",
        "            gt_index = i\n",
        "            gt_dict = sorted_batch[i].copy()\n",
        "            break\n",
        "    gt_dict['tag'] = 'ground-truth'\n",
        "    gt_dict['gid'] = gt[1]\n",
        "\n",
        "    if gt_index == None: # not enough options\n",
        "        print(\"Gt is not found. Possibly use a difference location than the distractor.\")\n",
        "        print(f\"Gt: {gt[0]}\")\n",
        "        print(f\"Dt: {distractor['text']}\\n\\n\")\n",
        "        left_over_subjs.append(subject)\n",
        "        continue \n",
        "    elif gt_index > 46:\n",
        "        left_over_subjs.append(subject)\n",
        "        print(f\"Skipping this case because {gt[0]} is ranked {gt_index} and no room for other options.\")\n",
        "        continue \n",
        "    else:    \n",
        "        local_tmp.append(gt_dict)\n",
        "        candidate_verb_phrases.append(gt_dict['vp']) # need to append gt first\n",
        "\n",
        "        local_tmp.append(distractor)\n",
        "        candidate_verb_phrases.append(distractor['vp'])\n",
        "\n",
        "        for item in sorted_batch[-3:]:\n",
        "            option = item.copy()\n",
        "            option['tag'] = 'option'\n",
        "            option['gid'] = gt[1]\n",
        "            local_tmp.append(option)\n",
        "            candidate_verb_phrases.append(option['vp'])\n",
        "\n",
        "        print(f\"Group {gt[1]}\\n{candidate_verb_phrases}\")\n",
        "        if check_cos_sim(model, candidate_verb_phrases, 0.73): # tuned threshold\n",
        "            verb_candidate_groups[gt[1]] = local_tmp\n",
        "            print(f\"Group {gt[1]} Success\\n\")\n",
        "            ctr += 1\n",
        "        else:\n",
        "            print(f\"Group {gt[1]} Failed because of similarity check\\n\")\n",
        "            left_over_subjs.append(subject)\n",
        "\n",
        "print(f\"=====================\\nTotal valid questions (Verb): {ctr-1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(left_over_subjs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "left_over_bases = []\n",
        "for sent_dict in base_sentences:\n",
        "    if sent_dict['subj'] in left_over_subjs:\n",
        "        left_over_bases.append(sent_dict) \n",
        "len(left_over_bases)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verb question formulation with templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4lkO6-RXOtS"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "verb_questions = []\n",
        "for group_id, sent_list in verb_candidate_groups.items():\n",
        "    question = {}\n",
        "    ppl_vp = {}\n",
        "    tmp_vp_list = []\n",
        "    id, gt_subj, gt_be, gt_verb, gt_loc, dt_verb = None, None, None, None, None, None\n",
        "    for sent in sent_list:\n",
        "        if sent['tag'] == 'ground-truth':\n",
        "            id = sent['gid']\n",
        "            gt_subj = sent['subj']\n",
        "            gt_be = sent['be']\n",
        "            gt_verb = sent['vp']\n",
        "            gt_loc = sent['loc']\n",
        "        elif sent['tag'] == 'distractor':\n",
        "            dt_verb = sent['vp']\n",
        "        ppl_vp[sent['vp']] = sent['ppl'] # it represents the sentence's ppl\n",
        "        tmp_vp_list.append(sent['vp'])\n",
        "\n",
        "    assert(any([id, gt_subj, gt_be, gt_verb, gt_loc, dt_verb]) != None)\n",
        "    question['id'] = id\n",
        "    question['subj'] = gt_subj\n",
        "    question['be'] = gt_be\n",
        "    question['loc'] = gt_loc\n",
        "    question['gt_vp'] = gt_verb\n",
        "    question['dt_vp'] = dt_verb\n",
        "    question['ppl'] = ppl_vp\n",
        "\n",
        "    assert(len(tmp_vp_list) == 5)\n",
        "    random.shuffle(tmp_vp_list)  # we shuffle the option's list\n",
        "    ans_idx = tmp_vp_list.index(gt_verb)\n",
        "    ans_idx_dt = tmp_vp_list.index(dt_verb)\n",
        "\n",
        "    # gt_subj_the = replace_a_or_the(gt_subj, replace='a')\n",
        "    # gt_subj_a = replace_a_or_the(gt_subj, replace='the')\n",
        "    max_ppl_verb = max(ppl_vp, key=ppl_vp.get)\n",
        "\n",
        "    # multiple choice question\n",
        "    choice = f\"What {gt_be} {gt_subj} doing {gt_loc}?\\nA. {tmp_vp_list[0]}\\nB. {tmp_vp_list[1]}\\nC. {tmp_vp_list[2]}\\nD. {tmp_vp_list[3]}\\nE. {tmp_vp_list[4]}\"\n",
        "    # binary question - true\n",
        "    binary_gt = f\"Does the image show that {gt_subj} {gt_be} {gt_verb} {gt_loc}?\"\n",
        "    # binary question - false\n",
        "    binary_dt = f\"Does the image show that {gt_subj} {gt_be} {dt_verb} {gt_loc}?\"\n",
        "    # binary question - comparision\n",
        "    binary_co = f\"Does the image show that {gt_subj} {gt_be} {max_ppl_verb} {gt_loc}?\"\n",
        "    # open question\n",
        "    open_question = f\"What {gt_be} {gt_subj} doing {gt_loc}?\"\n",
        "\n",
        "    question['choice'] = choice\n",
        "    question['choice answer'] = index_to_letter[ans_idx]\n",
        "    question['choice distractor answer'] = index_to_letter[ans_idx_dt]\n",
        "    question['binary-yes'] = binary_gt\n",
        "    question['binary-yes answer'] = \"Yes.\"\n",
        "    question['binary-no'] = binary_dt\n",
        "    question['binary-no answer'] = \"No.\"\n",
        "    question['binary-cp'] = binary_co\n",
        "    question['binary-cp answer'] = \"No.\"\n",
        "    question['open'] = open_question\n",
        "    question['open answer'] = gt_verb\n",
        "    question['image prompt'] = f\"Generate an image of {gt_subj} {gt_verb} {gt_loc}.\"\n",
        "\n",
        "    verb_questions.append(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YAbr4TjqNCW"
      },
      "outputs": [],
      "source": [
        "with open(f'verb_questions_vicuna_0302_partB.json', 'w') as f:\n",
        "    json.dump(verb_questions, f)\n",
        "\n",
        "with open('verb_questions_vicuna_0302_partB-h.txt', 'w') as outfile:\n",
        "    with open('verb_questions_vicuna_0302_partB.json', 'r') as infile:\n",
        "        j_list = json.load(infile)\n",
        "        for question in j_list:\n",
        "            outfile.write(f\"Question{question['id']}:\\n\\n{question['image prompt']}\\n{question['choice']}\\n\")\n",
        "            outfile.write(f\"Answer: {question['choice answer']}\\n\")\n",
        "            outfile.write(f\"Distrator: {question['choice distractor answer']}\\n\\n\")\n",
        "            outfile.write(f\"{question['binary-yes']}\\nAnswer: {question['binary-yes answer']}\\n\")\n",
        "            outfile.write(f\"{question['binary-no']}\\nAnswer: {question['binary-no answer']}\\n\")\n",
        "            outfile.write(f\"{question['binary-cp']}\\nAnswer: {question['binary-cp answer']}\\n\\n\")\n",
        "            outfile.write(f\"{question['open']}\\nAnswer: {question['open answer']}\\n\\n\")\n",
        "            outfile.write(f\"PPL: {question['ppl']}\\n\\n\")\n",
        "            outfile.write(\"=\"*10)\n",
        "            outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Location Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ7GruNee7md"
      },
      "source": [
        "### Pure location phrases (*for tuning threshold*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0mdyCFee9bh",
        "outputId": "783cd746-359e-4247-84a6-00333a17ac53"
      },
      "outputs": [],
      "source": [
        "# location phrase test case construction\n",
        "loc_candidate_groups = {}\n",
        "ctr = 1\n",
        "\n",
        "for sent_dict in base_sentences:\n",
        "    subject = sent_dict[\"subj\"]\n",
        "    verb_phrase = sent_dict[\"vp\"]\n",
        "    location = sent_dict[\"loc\"]\n",
        "    candidate_batch = []\n",
        "    for sentence in sent_data:\n",
        "        if sentence['subj'] == subject and sentence['vp'] == verb_phrase:\n",
        "            candidate_batch.append(sentence)\n",
        "    sorted_batch = sorted(candidate_batch, key=lambda x: x['ppl'])\n",
        "    assert(len(sorted_batch) == 50)\n",
        "\n",
        "    candidate_locs = []\n",
        "    distractor = sent_dict.copy()\n",
        "    gt = sorted_batch[-4].copy()\n",
        "    candidate_locs.append(gt['loc']) # need to append gt first\n",
        "    candidate_locs.append(distractor['loc'])\n",
        "\n",
        "    for item in sorted_batch[-3:]:\n",
        "        candidate_locs.append(item['loc'])\n",
        "\n",
        "    loc_candidate_groups[ctr] = candidate_locs\n",
        "    ctr += 1\n",
        "\n",
        "print(f\"=====================\\nTotal valid questions: {ctr-1}\")\n",
        "with open('loc_options.json', 'w') as f:\n",
        "    json.dump(loc_candidate_groups, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jncET1_3kqm8"
      },
      "source": [
        "### Location candidates selection w/o ground-truth images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXBPdmRrL5uy",
        "outputId": "6cfdba31-0cc7-438c-9724-699ab49bceda"
      },
      "outputs": [],
      "source": [
        "# location test case construction\n",
        "location_candidate_groups = {}\n",
        "\n",
        "ctr = 1\n",
        "for sent_dict in base_sentences:\n",
        "    subject = sent_dict[\"subj\"]\n",
        "    verb_phrase = sent_dict[\"vp\"]\n",
        "    location = sent_dict[\"loc\"]\n",
        "    candidate_batch = []\n",
        "    for sentence in sent_data_vicuna:\n",
        "        if sentence['subj'] == subject and sentence['vp'] == verb_phrase:\n",
        "            candidate_batch.append(sentence)\n",
        "    sorted_batch = sorted(candidate_batch, key=lambda x: x['ppl'])\n",
        "    assert(len(sorted_batch) == 50)\n",
        "\n",
        "    gt_index = random.randint(40, 43)\n",
        "    gt = sorted_batch[gt_index].copy()\n",
        "    distractor = sent_dict.copy()\n",
        "    option1 = sorted_batch[45].copy()\n",
        "    option2 = sorted_batch[47].copy()\n",
        "    option3 = sorted_batch[49].copy()\n",
        "\n",
        "    chances = {'option1': 1, 'option2': 1, 'option3': 1}\n",
        "    gt_indices = [40, 41, 42, 43]\n",
        "    gt_indices.remove(gt_index)\n",
        "\n",
        "    need_further_iteration = True\n",
        "    candidate_sentences = [gt, distractor, option1, option2, option3]\n",
        "    while need_further_iteration:\n",
        "        candidate_loc_phrases = [item['loc'] for item in candidate_sentences]\n",
        "        print(f\"Group {ctr}: {candidate_loc_phrases}\")\n",
        "        conflicts = check_cos_sim(model, candidate_loc_phrases, 0.63) # tuned threshold\n",
        "        if len(conflicts) == 0:\n",
        "            print(f\"Group {ctr} Succeed.\\n========\")\n",
        "            candidate_sentences[0]['tag'] = 'ground-truth'\n",
        "            candidate_sentences[1]['tag'] = 'distractor'\n",
        "            candidate_sentences[2]['tag'] = 'option1'\n",
        "            candidate_sentences[3]['tag'] = 'option2'\n",
        "            candidate_sentences[4]['tag'] = 'option3'\n",
        "            for sent in candidate_sentences:\n",
        "                sent['gid'] = ctr\n",
        "            location_candidate_groups[ctr] = candidate_sentences\n",
        "            ctr += 1\n",
        "            need_further_iteration = False\n",
        "        else:\n",
        "            resolved_all_conflicts = True\n",
        "            gt_needs_to_change = True if (0, 1) in conflicts else False\n",
        "            if gt_needs_to_change:\n",
        "                if len(gt_indices) == 0:\n",
        "                    print(f\"Group {ctr} Discarded due to unresolved gt-dt conflicts.\")\n",
        "                    resolved_all_conflicts = False\n",
        "                    need_further_iteration = False\n",
        "                    break\n",
        "                else:\n",
        "                    new_gt_index = random.choice(gt_indices)\n",
        "                    gt_indices.remove(new_gt_index)\n",
        "                    gt = sorted_batch[new_gt_index].copy()\n",
        "                    candidate_sentences[0] = gt\n",
        "                    conflicts = list(filter(lambda x: x[0] != 0, conflicts)) # options with gt are excluded\n",
        "\n",
        "            options_set = set()\n",
        "            for conflict in conflicts:\n",
        "                options_set.add(conflict[1])\n",
        "            print(options_set)\n",
        "            \n",
        "            for option in options_set:                    \n",
        "                if option == 2:  # Conflict with option1\n",
        "                    if chances['option1'] > 0:\n",
        "                        option1 = sorted_batch[44].copy()\n",
        "                        chances['option1'] -= 1\n",
        "                        candidate_sentences[2] = option1\n",
        "                    else:\n",
        "                        resolved_all_conflicts = False\n",
        "                        break\n",
        "                elif option == 3:  # Conflict with option2\n",
        "                    if chances['option2'] > 0:\n",
        "                        option2 = sorted_batch[46].copy()\n",
        "                        chances['option2'] -= 1\n",
        "                        candidate_sentences[3] = option2\n",
        "                    else:\n",
        "                        resolved_all_conflicts = False\n",
        "                        break\n",
        "                elif option == 4:  # Conflict with option3\n",
        "                    if chances['option3'] > 0:\n",
        "                        option3 = sorted_batch[48].copy()\n",
        "                        chances['option3'] -= 1\n",
        "                        candidate_sentences[4] = option3\n",
        "                    else:\n",
        "                        resolved_all_conflicts = False\n",
        "                        break\n",
        "            \n",
        "            if not resolved_all_conflicts:\n",
        "                print(f\"Group {ctr} Discarded due to unresolved option conflicts.\")\n",
        "                # print(candidate_sentences)\n",
        "                print(conflicts)\n",
        "                print(chances)\n",
        "                need_further_iteration = False\n",
        "\n",
        "print(f\"=====================\\nTotal valid questions (location): {ctr-1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Location candidates selection w/ ground-truth images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('/home/liu/temp_question/ground_truth_sentences_2_24.json', 'r') as f:\n",
        "    ground_truth = json.load(f)\n",
        "ground_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# location phrase test case construction\n",
        "# legacy selection logic of options = sorted_batch[-3:] is applied here\n",
        "verb_candidate_groups = {}\n",
        "ctr = 1\n",
        "for sent_dict in base_sentences:\n",
        "    subject = sent_dict[\"subj\"]\n",
        "    verb_phrase = sent_dict[\"vp\"]\n",
        "    location = sent_dict[\"loc\"]\n",
        "\n",
        "    candidate_batch = []\n",
        "    for sentence in sent_data_vicuna:\n",
        "        if sentence['subj'] == subject and sentence['vp'] == verb_phrase:\n",
        "            candidate_batch.append(sentence)\n",
        "    sorted_batch = sorted(candidate_batch, key=lambda x: x['ppl'])\n",
        "    assert(len(sorted_batch) == 50)\n",
        "    candidate_loc_phrases = []\n",
        "    local_tmp = []\n",
        "\n",
        "    try:\n",
        "        gt = ground_truth[subject]  # {subject: [whole text, qid]}\n",
        "    except:\n",
        "        left_over_subjs.append(subject)\n",
        "        continue\n",
        "\n",
        "    distractor = sent_dict.copy()\n",
        "    distractor['tag'] = 'distractor'\n",
        "    distractor['gid'] = gt[1]\n",
        "\n",
        "    gt_dict = {}\n",
        "    gt_index = None\n",
        "    for i in range(len(sorted_batch)):\n",
        "        if sorted_batch[i]['text'] == gt[0]:\n",
        "            gt_index = i\n",
        "            gt_dict = sorted_batch[i].copy()\n",
        "            break\n",
        "    gt_dict['tag'] = 'ground-truth'\n",
        "    gt_dict['gid'] = gt[1]\n",
        "\n",
        "    if gt_index == None: # not enough options\n",
        "        print(\"Gt is not found. Possibly use a difference verb phrase than the distractor.\")\n",
        "        print(f\"Gt: {gt[0]}\")\n",
        "        print(f\"Dt: {distractor['text']}\\n\\n\")\n",
        "        left_over_subjs.append(subject)\n",
        "        continue \n",
        "    elif gt_index > 46:\n",
        "        left_over_subjs.append(subject)\n",
        "        print(f\"Skipping this case because {gt[0]} is ranked {gt_index} and no room for other options.\")\n",
        "        continue \n",
        "    else:    \n",
        "        local_tmp.append(gt_dict)\n",
        "        candidate_loc_phrases.append(gt_dict['vp']) # need to append gt first\n",
        "\n",
        "        local_tmp.append(distractor)\n",
        "        candidate_loc_phrases.append(distractor['vp'])\n",
        "\n",
        "        for item in sorted_batch[-3:]:\n",
        "            option = item.copy()\n",
        "            option['tag'] = 'option'\n",
        "            option['gid'] = gt[1]\n",
        "            local_tmp.append(option)\n",
        "            candidate_loc_phrases.append(option['vp'])\n",
        "\n",
        "        print(f\"Group {gt[1]}\\n{candidate_loc_phrases}\")\n",
        "        if check_cos_sim(model, candidate_loc_phrases, 0.63): # tuned threshold\n",
        "            verb_candidate_groups[gt[1]] = local_tmp\n",
        "            print(f\"Group {gt[1]} Success\\n\")\n",
        "            ctr += 1\n",
        "        else:\n",
        "            print(f\"Group {gt[1]} Failed because of similarity check\\n\")\n",
        "            left_over_subjs.append(subject)\n",
        "\n",
        "print(f\"=====================\\nTotal valid questions (Verb): {ctr-1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Location question formulation with templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GWtL6jaoDpu"
      },
      "outputs": [],
      "source": [
        "loc_questions = []\n",
        "for group_id, sent_list in location_candidate_groups.items():\n",
        "    question = {}\n",
        "    ppl_loc = {}\n",
        "    tmp_loc_list = []\n",
        "    id, gt_subj, gt_be, gt_verb, gt_loc, dt_loc = None, None, None, None, None, None\n",
        "    for sent in sent_list:\n",
        "        if sent['tag'] == 'ground-truth':\n",
        "            id = sent['gid']\n",
        "            gt_subj = sent['subj']\n",
        "            gt_be = sent['be']\n",
        "            gt_verb = sent['vp']\n",
        "            gt_loc = sent['loc']\n",
        "        elif sent['tag'] == 'distractor':\n",
        "            dt_loc = sent['loc']\n",
        "        ppl_loc[sent['loc']] = sent['ppl']\n",
        "        tmp_loc_list.append(sent['loc'])\n",
        "\n",
        "    assert(any([id, gt_subj, gt_be, gt_verb, gt_loc, dt_loc]) != None)\n",
        "    question['id'] = id\n",
        "    question['subj'] = gt_subj\n",
        "    question['be'] = gt_be\n",
        "    question['vp'] = gt_verb\n",
        "    question['gt_loc'] = gt_loc\n",
        "    question['dt_loc'] = dt_loc\n",
        "    question['ppl'] = ppl_loc\n",
        "\n",
        "    assert(len(tmp_loc_list) == 5)\n",
        "    random.shuffle(tmp_loc_list) # we shuffle the option's list\n",
        "    ans_idx = tmp_loc_list.index(gt_loc)\n",
        "    ans_idx_dt = tmp_loc_list.index(dt_loc)\n",
        "\n",
        "    # gt_subj_the = replace_a_or_the(gt_subj, 'a')\n",
        "    # gt_subj_a = replace_a_or_the(gt_subj, 'the')\n",
        "    max_ppl_loc = max(ppl_loc, key=ppl_loc.get)\n",
        "\n",
        "    choice = f\"Where {gt_be} {gt_subj} {gt_verb}?\\nA. {tmp_loc_list[0]}\\nB. {tmp_loc_list[1]}\\nC. {tmp_loc_list[2]}\\nD. {tmp_loc_list[3]}\\nE. {tmp_loc_list[4]}\"\n",
        "    # binary question - true\n",
        "    binary_gt = f\"Does the image show that {gt_subj} {gt_be} {gt_verb} {gt_loc}?\"\n",
        "    # binary question - false\n",
        "    binary_dt = f\"Does the image show that {gt_subj} {gt_be} {gt_verb} {dt_loc}?\"\n",
        "    # binary question - comparision\n",
        "    binary_co = f\"Does the image show that {gt_subj} {gt_be} {gt_verb} {max_ppl_loc}?\"\n",
        "\n",
        "    # open question\n",
        "    open_question = f\"Where {gt_be} {gt_subj} {gt_verb}?\"\n",
        "\n",
        "    question['choice'] = choice\n",
        "    question['choice answer'] = index_to_letter[ans_idx]\n",
        "    question['choice distractor answer'] = index_to_letter[ans_idx_dt]\n",
        "    question['binary-yes'] = binary_gt\n",
        "    question['binary-yes answer'] = \"Yes.\"\n",
        "    question['binary-no'] = binary_dt\n",
        "    question['binary-no answer'] = \"No.\"\n",
        "    question['binary-cp'] = binary_co\n",
        "    question['binary-cp answer'] = \"No.\"\n",
        "    question['open'] = open_question\n",
        "    question['open answer'] = gt_loc\n",
        "    question['image prompt'] = f\"Generate an image of {gt_subj} {gt_verb} {gt_loc}.\"\n",
        "\n",
        "    loc_questions.append(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsuTAui4mJyq"
      },
      "outputs": [],
      "source": [
        "with open('loc_questions_vicuna_0302_full.json', 'w') as f:\n",
        "    json.dump(loc_questions, f)\n",
        "\n",
        "with open('loc_questions_vicuna_0302_full-h.txt', 'w') as outfile:\n",
        "    with open('loc_questions_vicuna_0302_full.json', 'r') as infile:\n",
        "        j_list = json.load(infile)\n",
        "        for question in j_list:\n",
        "            outfile.write(f\"Question{question['id']}:\\n\\n{question['image prompt']}\\n{question['choice']}\\n\")\n",
        "            outfile.write(f\"Answer: {question['choice answer']}\\n\")\n",
        "            outfile.write(f\"Distractor: {question['choice distractor answer']}\\n\\n\")\n",
        "            outfile.write(f\"{question['binary-yes']}\\nAnswer: {question['binary-yes answer']}\\n\")\n",
        "            outfile.write(f\"{question['binary-no']}\\nAnswer: {question['binary-no answer']}\\n\")\n",
        "            outfile.write(f\"{question['binary-cp']}\\nAnswer: {question['binary-cp answer']}\\n\\n\")\n",
        "            outfile.write(f\"{question['open']}\\nAnswer: {question['open answer']}\\n\\n\")\n",
        "            outfile.write(f\"PPL: {question['ppl']}\\n\\n\")\n",
        "            outfile.write(\"=\"*10)\n",
        "            outfile.write('\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2jScnoNSrWAV",
        "fv8YsTQFjndL",
        "moceLPp5jzfp",
        "cQ7GruNee7md"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
